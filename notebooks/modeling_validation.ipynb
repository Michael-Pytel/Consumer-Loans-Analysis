{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['FINALIZED_LOAN']\n",
    "X_train = df.drop(columns=\"FINALIZED_LOAN\")\n",
    "\n",
    "# Validation data\n",
    "y_val = df_val['FINALIZED_LOAN']\n",
    "X_val = df_val.drop(columns=\"FINALIZED_LOAN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.06513071, 1.07501388, 0.96744442, 0.97888851, 0.9278779 ,\n",
       "        0.9478848 ]),\n",
       " 'score_time': array([0.03900313, 0.03500056, 0.04201269, 0.04054379, 0.05254436,\n",
       "        0.03602886]),\n",
       " 'test_score': array([0.5323741 , 0.55414909, 0.5567867 , 0.54700855, 0.6       ,\n",
       "        0.55827338])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "scores = cross_validate(model, X_train, y_train, cv= 6, n_jobs=1, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n",
      "Accuracy Score: 0.8586092715231788\n",
      "Fold 2 of 5\n",
      "Accuracy Score: 0.8364238410596027\n",
      "Fold 3 of 5\n",
      "Accuracy Score: 0.8575687313680026\n",
      "Fold 4 of 5\n",
      "Accuracy Score: 0.851937727724412\n",
      "Fold 5 of 5\n",
      "Accuracy Score: 0.8353759523020868\n"
     ]
    }
   ],
   "source": [
    "# Initialize stratified k-fold\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# Initialize a variable to keep track of fold number\n",
    "fold = 1\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('Fold {} of {}'.format(fold, kf.n_splits))\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    xtr, xvl = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytr, yvl = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the decision tree classifier\n",
    "    model = DecisionTreeClassifier(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    pred_val = model.predict(xvl)\n",
    "    \n",
    "    # Calculate and print accuracy score\n",
    "    score = accuracy_score(yvl, pred_val)\n",
    "    print('Accuracy Score:', score)\n",
    "    \n",
    "    # Increment fold number\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy Score: 0.8757341576506955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the random forest classifier on the entire training set\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "rf_pred_val = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "rf_val_score = accuracy_score(y_val, rf_pred_val)\n",
    "print('Random Forest Validation Accuracy Score:', rf_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Score: 0.8528593508500772\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the decision tree classifier on the entire training set\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "val_score = accuracy_score(y_val, pred_val)x\n",
    "print('Validation Accuracy Score:', val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Score: 0.8528593508500772\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the decision tree classifier on the entire training set\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "val_score = accuracy_score(y_val, pred_val)x\n",
    "print('Validation Accuracy Score:', val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy Score: 0.8537867078825347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the logistic regression classifier on the entire training set\n",
    "logistic_model = LogisticRegression(random_state=1)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "logistic_pred_val = logistic_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "logistic_val_score = accuracy_score(y_val, logistic_pred_val)\n",
    "print('Logistic Regression Validation Accuracy Score:', logistic_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Accuracy Score: 0.887789799072643\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert the DataFrame into DMatrix format (required for XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set hyperparameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Use binary classification\n",
    "    'eval_metric': 'error',           # Evaluate using classification error\n",
    "    'seed': 1                         # Set random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 436  # Number of boosting rounds (you can tune this hyperparameter)\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "xgb_pred_val = xgb_model.predict(dval)\n",
    "xgb_pred_val_binary = [1 if p > 0.5 else 0 for p in xgb_pred_val]\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "xgb_val_score = accuracy_score(y_val, xgb_pred_val_binary)\n",
    "print('XGBoost Validation Accuracy Score:', xgb_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2576,  158],\n",
       "       [ 205,  296]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate confusion matrix\n",
    "xgb_conf_matrix = confusion_matrix(y_val, xgb_pred_val_binary)\n",
    "xgb_conf_matrix\n",
    "# Plot confusion matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(xgb_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "# plt.xlabel('Predicted labels')\n",
    "# plt.ylabel('True labels')\n",
    "# plt.title('XGBoost Confusion Matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Validation Accuracy Score: 0.8686244204018547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Gradient Boosting Classifier on the entire training set\n",
    "gb_model = GradientBoostingClassifier(random_state=1)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "gb_pred_val = gb_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy score on the validation set\n",
    "gb_val_score = accuracy_score(y_val, gb_pred_val)\n",
    "print('Gradient Boosting Classifier Validation Accuracy Score:', gb_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "y_train = df['FINALIZED_LOAN']\n",
    "X_train = df.drop(columns=\"FINALIZED_LOAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "Accuracy Score: 0.890728476821192\n",
      "Fold 2 of 10\n",
      "Accuracy Score: 0.8920529801324504\n",
      "Fold 3 of 10\n",
      "Accuracy Score: 0.8880794701986755\n",
      "Fold 4 of 10\n",
      "Accuracy Score: 0.8986754966887417\n",
      "Fold 5 of 10\n",
      "Accuracy Score: 0.8986754966887417\n",
      "Fold 6 of 10\n",
      "Accuracy Score: 0.8980132450331125\n",
      "Fold 7 of 10\n",
      "Accuracy Score: 0.8933774834437086\n",
      "Fold 8 of 10\n",
      "Accuracy Score: 0.8933068257123923\n",
      "Fold 9 of 10\n",
      "Accuracy Score: 0.8840291583830351\n",
      "Fold 10 of 10\n",
      "Accuracy Score: 0.8913187541418157\n"
     ]
    }
   ],
   "source": [
    "# Initialize stratified k-fold\n",
    "kf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Initialize a variable to keep track of fold number\n",
    "fold = 1\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('Fold {} of {}'.format(fold, kf.n_splits))\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    xtr, xvl = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytr, yvl = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the decision tree classifier\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    pred_val = model.predict(xvl)\n",
    "    \n",
    "    # Calculate and print accuracy score\n",
    "    score = accuracy_score(yvl, pred_val)\n",
    "    print('Accuracy Score:', score)\n",
    "    \n",
    "    # Increment fold number\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize stratified k-fold\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize a variable to keep track of fold number\u001b[39;00m\n",
      "\u001b[0;32m      5\u001b[0m fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize stratified k-fold\n",
    "kf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Initialize a variable to keep track of fold number\n",
    "fold = 1\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(X_train, y_train):\n",
    "    print('Fold {} of {}'.format(fold, kf.n_splits))\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    xtr, xvl = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytr, yvl = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the decision tree classifier\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    pred_val = model.predict(xvl)\n",
    "    \n",
    "    # Calculate and print accuracy score\n",
    "    score = f1_score(yvl, pred_val)\n",
    "    print('Accuracy Score:', score)\n",
    "    \n",
    "    # Increment fold number\n",
    "    fold += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
